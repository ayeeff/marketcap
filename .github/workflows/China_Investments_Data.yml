name: Scrape China Investments Data

on:
  schedule:
    # Run every month on the 1st at 00:00 UTC
    - cron: '0 0 1 * *'
  workflow_dispatch:  # Allows manual trigger from Actions tab
  push:
    branches: [ main ]  # Run on push to test

# CRITICAL: Grant write permissions to GITHUB_TOKEN
permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install selenium pandas PyGithub webdriver-manager
        
    - name: Set up Chrome
      uses: browser-actions/setup-chrome@latest
      with:
        chrome-version: stable
        
    - name: Run scraper
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Auto-generated by GitHub Actions
      run: |
        python china_investment_tracker.py
        
    - name: Upload debug files
      if: always()  # Run even if scraper fails
      uses: actions/upload-artifact@v4
      with:
        name: debug-output
        path: |
          *.html
          *.png
          *.csv
